<?rev

# PUT YOUR HANDLER NAMES  INTO THE GLOBAL gControllerHandlers AS A COMMA SEPARATED LIST
put "index" into gControllerHandlers


# THIS COMMAND WILL BE CALLED IF NONE IS SPECIFYED IN THE URI
command index
   -- put "https://audioboom.com/boos/3844212-fedwiki-authoring-tool" into droppedURL
   -- put "https://audioboom.com/boos/3836093-raspberrypad" into droppedURL
	put $_POST_RAW into dropJSON
   put json_ToArray (dropJSON) into dropArray
   put dropArray ["text"] into droppedURL

   -- put "https://en.wikipedia.org/wiki/Wiki" into droppedURL

   put mediwiki_ExtractPageTitleFromUrl (droppedURL) into pageTitle
   if pageTitle is empty then
		put "Error, this was not an mediawiki page url" into errorText
      put fedwiki_ConstructErrorJSON (errorText) into someJSON
   else
      -- put fedwiki_ConstructErrorJSON (pageTitle) into someJSON
      put fedwiki_FetchWikipediaPageJson (pageTitle) into someJSON
   end if

   put new header "Content-Type: application/json; charset=utf-8"
   put new header "Access-Control-Allow-Origin: *"
   put new header "Access-Control-Allow-Headers: Accept, Authorization, Content-Type"
   put new header "Access-Control-Allow-Methods: GET, POST, PUT, PATCH, DELETE OPTIONS, LINK, UNLINK"
   put someJSON
end index

function fedwiki_FetchWikipediaPageJson someTitle
   put fedwiki_FetchWikipediaPageArray (someTitle) into pageArray
   put json_FromArray (pageArray) into pageJson
   return pageJson
end fedwiki_FetchWikipediaPageJson

function mediwiki_ExtractPageTitleFromUrl someUrl
   -- https://en.wikipedia.org/wiki/Cat#/media/File:AfricanWildCat.jpg
   url_Deconstruct someUrl, someProtocol, urlDomain, urlPath, shortName, fileExtension, uName, pWord
   if urlDomain ends with ".wikipedia.org" is false then return empty

   set the itemdelimiter to "/"
   if item 1 of urlPath is not "wiki" then return empty
   return shortName
end mediwiki_ExtractPageTitleFromUrl

function fedwiki_ConstructErrorJSON errorText
   put fedwiki_ConstructNewPageArray ("Error", errorText) into someArray
   put json_FromArray (someArray) into someJSON
   return someJSON
end fedwiki_ConstructErrorJSON

function fedwiki_ConstructNewPageArray pageTitle, pSomeText
   put pageTitle into pageArray ["title"]
   if pSomeText is not empty then fedwiki_AddParagraphToPageArray pageArray, pSomeText
   put fedwiki_ConstructJournalArray (pageTitle) into pageArray ["journal"]
   return pageArray
end fedwiki_ConstructNewPageArray

command file_Deconstruct someFile, @someRoot, @shortName, @fileExtension
    -- was "deconstruct_File"
    -- should turn someRoot into someFolder and add "/" to end

    if someFile is empty then
        put the effective filename of this stack into someFile
    end if
    put someFile into someRoot
    put the itemdelimiter into originalDelim

    set the itemdelimiter to "/"
    put last item of someFile into shortName
    delete last item of someRoot

    if shortName contains "." then
        set the itemdelimiter to "."
        put last item of shortName into fileExtension
        delete last item of shortName
    else
        put empty into fileExtension
    end if
    set the itemdelimiter to originalDelim
end file_Deconstruct

command url_Deconstruct someUrl, @someProtocol, @urlDomain, @urlPath, @shortName, @fileExtension, @uName, @pWord
    /*
    -- from http://regexlib.com/REDetails.aspx?regexp_id=628
    -- put "(?:(?<protocol>http(?:s?)|ftp)(?:\:\/\/)) (?:(?<usrpwd>\w+\:\w+)(?:\@))? (?<domain>[^/\r\n\:]+)? (?<port>\:\d+)? (?<path>(?:\/.*)*\/)? (?<filename>.*?\.(?<ext>\w{2,4}))? (?<qrystr>\??(?:\w+\=[^\#]+)(?:\&?\w+\=\w+)*)* (?<bkmrk>\#.*)?" into someReg
    */

    set the itemdelimiter to ":"
    put item 1 of someUrl into someProtocol
    if someProtocol is among the items of "file:binFile:ftp:http:https" then
        put someUrl into someFile
        delete item 1 of someFile
        if char 1 to 2 of someFile = "//" then delete char 1 to 2 of someFile

        get offset("@", someFile)
        if it = 0 then
            put empty into uName
            put empty into pWord
        else
            put char 1 to (it - 1) of someFile into authBit
            repeat while char 1 of authBit is "/"
                delete char 1 of authBit
            end repeat
            if the number of items of authBit = 2 then
                put item 1 of authBit into uName
                put item 2 of authBit into pWord
                delete char 1 to it of someFile
            else
                -- "@" must be in url ignore
                put empty into uName
                put empty into pWord
            end if
        end if
        file_Deconstruct someFile, someRoot, shortName, fileExtension

        set the itemdelimiter to "/"
        put item 1 of someRoot into UrlDomain
        put item 2 to -1 of someRoot into urlPath
        return true
    else
        put empty into someProtocol
        put empty into UrlDomain
        put empty into urlPath
        put empty into shortName
        put empty into fileExtension
        put empty into uName
        put empty into pWord
        return false
    end if
end url_Deconstruct

command fedwiki_AddFactoryToPageArray @pageArray, pID
   put fedwiki_ConstructFactoryArray (pID) into itemArray
   fedwiki_PageArrayAddToEnd itemArray, pageArray
end fedwiki_AddFactoryToPageArray

command fedwiki_AddParagraphToPageArray @pageArray, someText, pID
   put fedwiki_ConstructStoryParagraphArray (someText, pID) into itemArray
   fedwiki_PageArrayAddToEnd itemArray, pageArray
end fedwiki_AddParagraphToPageArray

command fedwiki_AddToEndOfIndexArray dataOrArray, @someArray
   put item 2 of the extents of someArray into indexNum
   put someArray [indexNum]["id"] into afterID
   add 1 to indexNum
   put dataOrArray into someArray [indexNum]
   return afterID -- figure out what we just added it after
end fedwiki_AddToEndOfIndexArray

command fedwiki_AddToJournalArray @journalArray, itemArray, journalType, pAfterID, pMilliseconds
   if pMilliseconds is empty then put the milliseconds into pMilliseconds
   if pAfterID is not empty then
      put pAfterID into journalEntryArray ["after"]
   end if
   put pMilliseconds into journalEntryArray ["date"]
   put itemArray ["id"] into journalEntryArray ["id"]
   put itemArray into journalEntryArray ["item"]
   put journalType into journalEntryArray ["type"]

   fedwiki_AddToEndOfIndexArray journalEntryArray, journalArray
end fedwiki_AddToJournalArray

function fedwiki_ConstructFactoryArray pID
   if pID is empty then
      put text_Hash (the ticks & "factory") into pID
   end if
   put "factory" into factoryArray ["type"]
   put pID into factoryArray ["id"]
   return factoryArray
end fedwiki_ConstructFactoryArray

function fedwiki_ConstructJournalArray pageTitle
   put the milliseconds into journalArray [1]["date"]
   put empty into journalArray [1]["item"]["story"]
   put pageTitle into journalArray [1]["item"]["title"]
   put "create" into journalArray [1]["type"]
   return journalArray
end fedwiki_ConstructJournalArray

function fedwiki_ConstructNewFactoryPageArray pageTitle
   local pageArray
   put pageTitle into pageArray ["title"]
   put fedwiki_ConstructJournalArray (pageTitle) into pageArray ["journal"]
   fedwiki_AddFactoryToPageArray pageArray
   return pageArray
end fedwiki_ConstructNewFactoryPageArray

function fedwiki_ConstructStoryParagraphArray someText, pID
   if pID is empty then
      put text_Hash (the ticks & someText) into pID
   end if
   put someText into paragraphArray ["text"]
   put "paragraph" into paragraphArray ["type"]
   put pID into paragraphArray ["id"]
   return paragraphArray
end fedwiki_ConstructStoryParagraphArray

function fedwiki_ConvertWikipediaQueryArray wikipediaQueryArray
   put wikipediaQueryArray ["query"]["pages"] into pagesArray
   repeat for each key pageID in pagesArray
      put pagesArray [pageID] into pageArray

      put pageArray ["title"] into pageTitle
      put pageArray ["extract"] into pageExtract
      put pageArray ["terms"]["description"][1] into pageDescription
      exit repeat
   end repeat

   put fedwiki_ConstructNewFactoryPageArray (pageTitle) into pageArray
   fedwiki_AddParagraphToPageArray pageArray, pageDescription
   return pageArray
end fedwiki_ConvertWikipediaQueryArray

function fedwiki_FetchWikipediaPageArray someTitle
   put wikipedia_FetchPageStuff (someTitle) into someJSON
   put json_ToArray (someJSON) into wikipediaQueryArray
   put fedwiki_ConvertWikipediaQueryArray (wikipediaQueryArray) into pageArray
   return pageArray
end fedwiki_FetchWikipediaPageArray

command fedwiki_PageArrayAddToEnd storyItemArray, @pageArray
   -- this add a factory to the journal and a itemArray to the journal and story
   -- all with the same id
   put pageArray ["story"] into storyArray
   put pageArray ["journal"] into journalArray
   put storyItemArray ["id"] into itemID

   -- add the item to the end of the story
   fedwiki_AddToEndOfIndexArray storyItemArray, storyArray
   -- figure out what we just added it after
   -- this can be empty if it is the first entry
   put the result into afterID
   put storyArray into pageArray ["story"]

   -- 3) Now let's add the edit or add to the journal
   -- make the factory have the same id as the item we will add to the story
   put fedwiki_ConstructFactoryArray (itemID) into factoryArray
   -- now add a journal entry for adding after the id of the end paragraph
   fedwiki_AddToJournalArray journalArray, factoryArray, "add", afterID

   -- finally add the journal entry for editing the factory
   fedwiki_AddToJournalArray journalArray, storyItemArray, "edit"
   put journalArray into pageArray ["journal"]
end fedwiki_PageArrayAddToEnd

function json_FromArray pArray, pForceRootType, pPretty
   -- identical to (simply renamed) "ArrayToJSON"
   -- pArray - array to be encoded
   -- pForceRootType - can force the root to be an object if it looks like an array
   -- pPretty - include whitespace
   repeat for each key tKey in pArray
      if pArray[tKey] is an array then
         put "}" & json_FromArray (pArray[tKey]) into pArray[tKey]
      end if
   end repeat
   return (mergJSONEncode ("pArray", pForceRootType, pPretty))
end json_FromArray

function json_ToArray pJSON
   if pJSON is empty then return false
   try -- as otherwise an error with non-json causes script to exit
      local tArray,tKeys
      if pJSON is empty then return empty
      repeat for each line tKey in mergJSONDecode (pJSON,"tArray")
         put json_ToArray (tArray[tKey]) into tArray[tKey]
      end repeat
      return tArray
   catch e
      return empty
   end try
end json_ToArray

function md5_Hash someText
   local hexDigest
   put md5digest (someText) into someBinaryData
   return binarydecode ("H*", someBinaryData, hexDigest)
   return hexDigest
end md5_Hash

function mediawiki_FetchPageBits pageTitle, pProps, pOtherBits, pApiStem, pFormat
   if pProps is empty then put "revisions" into pProps
   if pFormat is empty then put "json" into pFormat
   if pApiStem is empty then put wikipedia_GetApiRoot() into pApiStem -- wikpedia

   put urlencode(pageTitle) into pageTitle
   put merge("[[pApiStem]]?action=query&prop=[[pProps]]&titles=[[pageTitle]]&format=[[pFormat]]") into someURL
   if pOtherBits is not empty then put "&" &  pOtherBits after someURL
   put url someUrl into someResult
   return someResult
end mediawiki_FetchPageBits

function sha1_Hash someData
   local hexDigest
   put sha1digest (someData) into someBinaryData
   get binarydecode ("H*", someBinaryData, hexDigest)
   return hexDigest
end sha1_Hash

function text_Hash someData, pWhichDigest
   if pWhichDigest = "sha1" then
      return sha1_Hash (someData)
   else
      return md5_Hash (someData)
   end if
end text_Hash

function wikipedia_FetchPageStuff pageTitle
   put mediawiki_FetchPageBits (pageTitle, "extracts|links|extlinks|categories|images|pageimages|pageterms", "exintro=true") into someJSON
   return someJSON
end wikipedia_FetchPageStuff

function wikipedia_GetApiRoot
   return "https://en.wikipedia.org/w/api.php"
end wikipedia_GetApiRoot
